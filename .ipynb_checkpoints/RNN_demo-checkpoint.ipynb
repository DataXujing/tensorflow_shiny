{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN Demo using waves**\n",
    "Inspired by https://codesachin.wordpress.com/2016/01/23/predicting-trigonometric-waves-few-steps-ahead-with-lstms-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from numpy import array, sin, cos, pi\n",
    "from random import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn.rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creates the training data  \n",
    "**Changes:  \n",
    "  I changed the frequencies so they don't overlap  \n",
    "  I added more nonlinearities by adding the square and cube  \n",
    "  I changed the lag to 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Producing Training/Testing inputs+output\n",
    "\n",
    "#Random initial angles\n",
    "angle1 = random()\n",
    "angle2 = random()\n",
    " \n",
    "#The total 2*pi cycle would be divided into 'frequency'\n",
    "#number of steps\n",
    "frequency1 = 333\n",
    "frequency2 = 211\n",
    "#This defines how many steps ahead we are trying to predict\n",
    "lag = 40\n",
    " \n",
    "def get_sample():\n",
    "    \"\"\"\n",
    "    Returns a [[sin value, cos value]] input.\n",
    "    \"\"\"\n",
    "    global angle1, angle2\n",
    "    angle1 += 2*pi/float(frequency1)\n",
    "    angle2 += 2*pi/float(frequency2)\n",
    "    angle1 %= 2*pi\n",
    "    angle2 %= 2*pi\n",
    "    return array([array([\n",
    "        5 + 5*sin(angle1) + 10*cos(angle2)**2,\n",
    "        7 + 7*sin(angle2)**3 + 14*cos(angle1)])])\n",
    " \n",
    "    \n",
    "sliding_window = []\n",
    " \n",
    "for i in range(lag - 1):\n",
    "    sliding_window.append(get_sample())\n",
    " \n",
    " \n",
    "def get_pair():\n",
    "    \"\"\"\n",
    "    Returns an (current, later) pair, where 'later' is 'lag'\n",
    "    steps ahead of the 'current' on the wave(s) as defined by the\n",
    "    frequency.\n",
    "    \"\"\"\n",
    " \n",
    "    global sliding_window\n",
    "    sliding_window.append(get_sample())\n",
    "    input_value = sliding_window[0]\n",
    "    output_value = sliding_window[-1]\n",
    "    sliding_window = sliding_window[1:]\n",
    "    return input_value, output_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets take a look at the input data that is created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_input1 = []\n",
    "actual_input2 = []\n",
    "actual_output1 = []\n",
    "actual_output2 = []\n",
    "x_axis = []\n",
    "\n",
    "for i in range(2000):\n",
    "    input_v, output_v = get_pair()\n",
    "    actual_input1.append(input_v[0][0])\n",
    "    actual_input2.append(input_v[0][1])\n",
    "    actual_output1.append(output_v[0][0])\n",
    "    actual_output2.append(output_v[0][1])\n",
    "    x_axis.append(i)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis, actual_input1, 'r-', x_axis, actual_output1, 'b-')\n",
    "plt.show()\n",
    "plt.plot(x_axis, actual_input2, 'r-', x_axis, actual_output2, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot X against Y\n",
    "plt.plot(actual_input1, actual_input2, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This input data is much more nonlinear and periodic than the original example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#Input Params\n",
    "input_dim = 2\n",
    " \n",
    "#To maintain state\n",
    "last_value = array([0 for i in range(input_dim)])\n",
    "last_derivative = array([0 for i in range(input_dim)])\n",
    " \n",
    " \n",
    "def get_total_input_output():\n",
    "    \"\"\"\n",
    "    Returns the overall Input and Output as required by the model.\n",
    "    The input is a concatenation of the wave values, their first and\n",
    "    second derivatives.\n",
    "    \"\"\"\n",
    "    global last_value, last_derivative\n",
    "    raw_i, raw_o = get_pair()\n",
    "    raw_i = raw_i[0]\n",
    "    l1 = list(raw_i)\n",
    "    derivative = raw_i - last_value\n",
    "    l2 = list(derivative)\n",
    "    last_value = raw_i\n",
    "    l3 = list(derivative - last_derivative)\n",
    "    last_derivative = derivative\n",
    "    return array([l1 + l2 + l3]), raw_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow model**  \n",
    "- 2 layer is tougher to use  \n",
    "- Get errors about shared variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input Params\n",
    "input_dim = 2\n",
    " \n",
    "##The Input Layer as a Placeholder\n",
    "#Since we will provide data sequentially, the 'batch size'\n",
    "#is 1.\n",
    "input_layer = tf.placeholder(tf.float32, [1, input_dim*3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_type = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create outputs\n",
    "output_W1 = tf.Variable(tf.truncated_normal([input_dim*3, input_dim]))\n",
    "output_b1 = tf.Variable(tf.zeros([input_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cell_type == 1:\n",
    "    lstm_layer1 = rnn_cell.BasicRNNCell(input_dim*3)\n",
    "    lstm_state1 = tf.Variable(tf.zeros([1, lstm_layer1.state_size]))\n",
    "    lstm_output1, lstm_state_output1 = lstm_layer1(input_layer, lstm_state1, scope=\"BasicRNN\")\n",
    "    lstm_update_op1 = lstm_state1.assign(lstm_state_output1)\n",
    "    final_output = tf.matmul(lstm_output1, output_W1) + output_b1\n",
    "if cell_type == 2:\n",
    "    lstm_layer2 = rnn_cell.GRUCell(input_dim*3)\n",
    "    lstm_state2 = tf.Variable(tf.zeros([1, lstm_layer2.state_size]))\n",
    "    lstm_output2, lstm_state_output2 = lstm_layer2(input_layer, lstm_state2, scope=\"GRUCell\")\n",
    "    lstm_update_op2 = lstm_state2.assign(lstm_state_output2)\n",
    "    final_output = tf.matmul(lstm_output2, output_W1) + output_b1\n",
    "if cell_type == 3:\n",
    "    lstm_layer3 = rnn_cell.BasicLSTMCell(input_dim*3)\n",
    "    lstm_state3 = tf.Variable(tf.zeros([1, lstm_layer3.state_size]))\n",
    "    lstm_output3, lstm_state_output3 = lstm_layer3(input_layer, lstm_state3, scope=\"BasicLSTM\")\n",
    "    lstm_update_op3 = lstm_state3.assign(lstm_state_output3)\n",
    "    final_output = tf.matmul(lstm_output3, output_W1) + output_b1\n",
    "if cell_type == 4:\n",
    "    lstm_layer4 = rnn_cell.BasicLSTMCell(input_dim*3)\n",
    "    lstm_layer4 = rnn_cell.MultiRNNCell([lstm_layer4]*2)\n",
    "    lstm_layer4 = rnn_cell.DropoutWrapper(lstm_layer4,output_keep_prob=0.8)\n",
    "    lstm_state4 = tf.Variable(tf.zeros([1, lstm_layer4.state_size]))\n",
    "    lstm_output4, lstm_state_output4 = lstm_layer4(input_layer, lstm_state4, scope=\"LSTM-2\")\n",
    "    lstm_update_op4 = lstm_state4.assign(lstm_state_output4)\n",
    "    final_output = tf.matmul(lstm_output4, output_W1) + output_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Input for correct output (for training)\n",
    "correct_output = tf.placeholder(tf.float32, [1, input_dim])\n",
    "\n",
    "##Calculate the Sum-of-Squares Error\n",
    "error = tf.pow(tf.sub(final_output, correct_output), 2)\n",
    "\n",
    "##The Optimizer\n",
    "#Adam works best\n",
    "train_step = tf.train.AdamOptimizer(0.0006).minimize(error)\n",
    "w_hist = tf.histogram_summary('weights', output_W1)\n",
    "b_hist = tf.histogram_summary('biases', output_b1)\n",
    "y_hist = tf.histogram_summary('y', final_output)\n",
    "\n",
    "##Session\n",
    "sess = tf.Session()\n",
    "#Initialize all Variables\n",
    "merged = tf.merge_summary([w_hist,b_hist,y_hist])\n",
    "tf.train.write_graph(sess.graph_def,'/tmp/tensor','graph.txt')\n",
    "writer = tf.train.SummaryWriter('/tmp/tensor/',sess.graph_def)\n",
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Training\n",
    " \n",
    "actual_output1 = []\n",
    "actual_output2 = []\n",
    "network_output1 = []\n",
    "network_output2 = []\n",
    "x_axis = []\n",
    " \n",
    " \n",
    "for i in range(3000):\n",
    "    input_v, output_v = get_total_input_output()\n",
    "    if cell_type == 1:\n",
    "        _, _, network_output, merge = sess.run([lstm_update_op1,\n",
    "                                     train_step,\n",
    "                                     final_output,merged],\n",
    "                                    feed_dict = {\n",
    "                                        input_layer: input_v,\n",
    "                                        correct_output: output_v})\n",
    "    if cell_type == 2:\n",
    "        _, _, network_output, merge = sess.run([lstm_update_op2,\n",
    "                                     train_step,\n",
    "                                     final_output,merged],\n",
    "                                    feed_dict = {\n",
    "                                        input_layer: input_v,\n",
    "                                        correct_output: output_v})\n",
    "    if cell_type == 3:\n",
    "        _, _, network_output, merge = sess.run([lstm_update_op3,\n",
    "                                     train_step,\n",
    "                                     final_output,merged],\n",
    "                                    feed_dict = {\n",
    "                                        input_layer: input_v,\n",
    "                                        correct_output: output_v})\n",
    "    if cell_type == 4:\n",
    "        _, _, network_output, merge = sess.run([lstm_update_op4,\n",
    "                                     train_step,\n",
    "                                     final_output,merged],\n",
    "                                    feed_dict = {\n",
    "                                        input_layer: input_v,\n",
    "                                        correct_output: output_v})\n",
    "    actual_output1.append(output_v[0][0])\n",
    "    actual_output2.append(output_v[0][1])\n",
    "    network_output1.append(network_output[0][0])\n",
    "    network_output2.append(network_output[0][1])\n",
    "    x_axis.append(i)\n",
    "    writer.add_summary(merge, i)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis, network_output1, 'r-', x_axis, actual_output1, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis, network_output2, 'r-', x_axis, actual_output2, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis[18500:19999], network_output2[18500:19999], 'r-', x_axis[18500:19999], actual_output2[18500:19999], 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis[0:15000], network_output2[0:15000], 'r-', x_axis[0:15000], actual_output2[0:15000], 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis[150:999], network_output2[150:999], 'r-', x_axis[150:999], actual_output2[150:999], 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis[0:250], network_output2[0:250], 'r-', x_axis[0:250], actual_output2[0:250], 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x_axis[78500:79999], network_output2[78500:79999], 'r-', x_axis[78500:79999], actual_output2[78500:79999], 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Testing\n",
    " \n",
    "for i in range(200):\n",
    "    get_total_input_output()\n",
    "#Flush LSTM state\n",
    "###NEED TO FIX THIS TO RUN MODEL CHOSEN ABOVE###\n",
    "sess.run(lstm_state4.assign(tf.zeros([1, lstm_layer4.state_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_actual_output1 = []\n",
    "test_actual_output2 = []\n",
    "test_network_output1 = []\n",
    "test_network_output2 = []\n",
    "test_x_axis = []\n",
    " \n",
    " \n",
    "for i in range(1000):\n",
    "    input_v, output_v = get_total_input_output()\n",
    "    _, network_output = sess.run([lstm_update_op4,\n",
    "                                  final_output],\n",
    "                                 feed_dict = {\n",
    "                                     input_layer: input_v,\n",
    "                                     correct_output: output_v})\n",
    " \n",
    "    test_actual_output1.append(output_v[0][0])\n",
    "    test_actual_output2.append(output_v[0][1])\n",
    "    test_network_output1.append(network_output[0][0])\n",
    "    test_network_output2.append(network_output[0][1])\n",
    "    test_x_axis.append(i)\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_x_axis, test_network_output1, 'r-', test_x_axis, test_actual_output1, 'b-')\n",
    "plt.show()\n",
    "plt.plot(test_x_axis, test_network_output2, 'r-', test_x_axis, test_actual_output2, 'b-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
